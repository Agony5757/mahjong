{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aiFrost2 import AgentFrost2, MahjongNetFrost2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from buffer import MahjongBufferFrost2\n",
    "import MahjongPy as mp\n",
    "from wrapper import EnvMahjong2\n",
    "import scipy.io as sio\n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "datetime_str = now.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "graphs = [tf.Graph(), tf.Graph(), tf.Graph(), tf.Graph() ]\n",
    "\n",
    "env = EnvMahjong2()\n",
    "\n",
    "num_tile_type = env.matrix_feature_size[0]\n",
    "num_each_tile = env.matrix_feature_size[1]\n",
    "num_vf = env.vector_feature_size\n",
    "\n",
    "agents = [AgentFrost2(nn=MahjongNetFrost2(graphs[i], agent_no=i, num_tile_type=num_tile_type, num_each_tile=num_each_tile, num_vf=num_vf),\n",
    "                      memory=MahjongBufferFrost2(size=4096, num_tile_type=num_tile_type, num_each_tile=num_each_tile, num_vf=num_vf),\n",
    "                      greedy=10.0 ** np.random.uniform(-1, 1),\n",
    "                      num_tile_type=num_tile_type, num_each_tile=num_each_tile, num_vf=num_vf)\n",
    "          for i in range(4)]\n",
    "\n",
    "\n",
    "episode_start = 256\n",
    "episode_savebuffer = 128\n",
    "mu_size = 40\n",
    "max_steps = agents[0].memory.episode_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  以下的代码可以让Agent读取保存的对局buffer， 如果comment掉就可以让Agent从头开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example \n",
    "# for i in range(4):\n",
    "#     buffer_path =  \"./buffer/Agent{}\".format(i) + \"-MahjongBufferFrost220190531-150059.pkl\"\n",
    "#     agents[i].memory.load(buffer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  以下的代码可以让Agent读取保存的网络， 如果comment掉就可以让Agent从头开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # example \n",
    "# for i in range(4):\n",
    "#     model_path =  \"../log/Agent{}\".format(i) + \"-20190531-150059-Game0/naiveAI.ckpt\"\n",
    "#     agents[i].nn.restore(model_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start!\n",
      "Model saved in path: ../log/Agent0-20190602-172734-Game0/naiveAI.ckpt\n",
      "Model saved in path: ../log/Agent1-20190602-172734-Game0/naiveAI.ckpt\n",
      "Model saved in path: ../log/Agent2-20190602-172734-Game0/naiveAI.ckpt\n",
      "Model saved in path: ../log/Agent3-20190602-172734-Game0/naiveAI.ckpt\n",
      " Game 76 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 126 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 169 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 172 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 177 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 242 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 278 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 288 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 543 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 700 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 701 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 756 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 776 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 1027 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 1031 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 1103 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 1194 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 1260 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 1294 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 1322Episode Length 0! Not recorded!\n",
      "Episode Length 0! Not recorded!\n",
      "Episode Length 0! Not recorded!\n",
      " \n",
      "ResultType.IntervalRyuuKyoku: Totally 150 steps\n",
      " Game 1334 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 1422 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 1707 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 1746 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 1778 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 1870 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 1871 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 1874 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 1966 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 1987 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 1991 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 2055 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 2061 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 2172 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 2281 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 2295 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 2346 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 2390 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 2409 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 2420 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 2457 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 2525 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 2633 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 2645 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 2685 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 2712 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 3025 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 3120 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 3140 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 3164 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 3243 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 3332 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 3359 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 3436 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 3516 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 3529 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 3580 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 3626 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 3634 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 3719 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 3822 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 3855 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 3912 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 3958 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4120 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4123 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 4194 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4212 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 4239 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4257 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4272 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4327 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4363 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4380 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4417 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 4441 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4647 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4723 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4733 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 4743 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4791 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4792 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4827 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4836 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4843 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 4865 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 4914 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 4930 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 4948 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 4987 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 5010 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 5016 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 5219 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 5280 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 5454 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 5587 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 5588 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 5619 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 5687 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 5825 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 5827 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 5877 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 5888 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 5963 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6114 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 6140 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 6189 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 6203 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6210 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 6245 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6291 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6370 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 6383 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6450 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6697 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 6755 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 6757 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6848 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 6878 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 6907 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 6945 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 7026 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 7053 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7127 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 7183 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7239 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 7268 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7356 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      "Buffer saved in path: ./buffer/Agent0-MahjongBufferFrost220190602-172734.pkl\n",
      " Game 7386 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      "Buffer saved in path: ./buffer/Agent1-MahjongBufferFrost220190602-172734.pkl\n",
      "Buffer saved in path: ./buffer/Agent2-MahjongBufferFrost220190602-172734.pkl\n",
      "Buffer saved in path: ./buffer/Agent3-MahjongBufferFrost220190602-172734.pkl\n",
      " Game 7448 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7515 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 7604 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 7651 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 7694 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 7752 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7819 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 7867 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7885 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7887 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 7918 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 7995 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 8007 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8151 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8186 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 8215 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8248 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8355 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 8394 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 8432 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8481 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8499 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8516 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8532 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 8651 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 8667 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 8688 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 8820 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 8946 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9003 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9021 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9070 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9206 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9222 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9256 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9268 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9312 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9320 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9457 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9611 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9651 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9677 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 9711 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 9770 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9772 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9844 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9878 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9921 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9981 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9994 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 9997 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 9999Model saved in path: ../log/Agent0-20190602-172734-Game10000/naiveAI.ckpt\n",
      "Model saved in path: ../log/Agent1-20190602-172734-Game10000/naiveAI.ckpt\n",
      "Model saved in path: ../log/Agent2-20190602-172734-Game10000/naiveAI.ckpt\n",
      "Model saved in path: ../log/Agent3-20190602-172734-Game10000/naiveAI.ckpt\n",
      " Game 10036 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 10106 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 10111 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 10228 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 10269 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 10354 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 10391 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 10406 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 10596 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 10719 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 10899 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 11112 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11133 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11271 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11319 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11348 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11361 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 11438 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11448 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 11528 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11575 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 11588 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 11685 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11712 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 11803 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 11930 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 11948 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12029 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12035 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12065 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12105 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12127 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12135 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12185 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12187 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12435 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12437 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12460 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12557 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 12589 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12634 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 12705 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12728 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12749 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12839 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 12841 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12916 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12928 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 12982 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13008 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13012 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13019 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13089 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13111 \n",
      "ResultType.IntervalRyuuKyoku: Totally 150 steps\n",
      " Game 13171 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13226 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13291 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13292 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13326 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13413 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13425 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13449 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13483 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 13502 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13508 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13543 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      " Game 13604 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 13646 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 13668 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13685 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 13728 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13742 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13743 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13770 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      " Game 13816 \n",
      "ResultType.RonAgari: Totally 150 steps\n",
      " Game 13821 \n",
      "ResultType.NoTileRyuuKyoku: Totally 150 steps\n",
      "Buffer saved in path: ./buffer/Agent0-MahjongBufferFrost220190602-172734.pkl\n",
      " Game 13840 \n",
      "ResultType.TsumoAgari: Totally 150 steps\n",
      "Buffer saved in path: ./buffer/Agent1-MahjongBufferFrost220190602-172734.pkl\n",
      "Buffer saved in path: ./buffer/Agent2-MahjongBufferFrost220190602-172734.pkl\n",
      "Buffer saved in path: ./buffer/Agent3-MahjongBufferFrost220190602-172734.pkl\n",
      " Game 13884"
     ]
    }
   ],
   "source": [
    "\n",
    "n_games = 1000000\n",
    "\n",
    "print(\"Start!\")\n",
    "\n",
    "for n in range(n_games):\n",
    "\n",
    "    if n % 10000 == 0:\n",
    "        for i in range(4):\n",
    "            agents[i].nn.save(model_dir=\"Agent{}-\".format(i) + datetime_str + \"-Game{}\".format(\n",
    "                n))  # save network parameters every 10000 episodes\n",
    "\n",
    "    for i in range(4):\n",
    "        if agents[i].memory.filled_size >= episode_savebuffer and agents[i].memory.tail % episode_savebuffer == 0:\n",
    "            agents[i].memory.save(\"./buffer/Agent{}-\".format(i) + \"MahjongBufferFrost2\" + datetime_str + \".pkl\")\n",
    "\n",
    "    print(\"\\r Game {}\".format(n), end='')\n",
    "\n",
    "    episode_dones = np.zeros([4, max_steps], dtype=np.float16)\n",
    "    episode_matrix_features = np.zeros([4, max_steps, num_tile_type, num_each_tile], dtype=np.float16)\n",
    "    episode_vector_features = np.zeros([4, max_steps, num_vf], dtype=np.float16)\n",
    "    episode_rewards = np.zeros([4, max_steps], dtype=np.float32)\n",
    "    episode_actions = np.zeros([4, max_steps], dtype=np.int32)\n",
    "    episode_policies = np.zeros([4, max_steps, mu_size], dtype=np.float32)\n",
    "\n",
    "\n",
    "    done = 0\n",
    "    #     policies = np.zeros([4,], dtype=np.int32)\n",
    "    actions = np.zeros([4, ], dtype=np.int32)\n",
    "    rs = np.zeros([4, ], dtype=np.float32)\n",
    "\n",
    "    this_states = env.reset()  ## for all players\n",
    "\n",
    "    next_aval_states = deepcopy(this_states)\n",
    "\n",
    "    next_matrix_features = np.zeros([4, num_tile_type, num_each_tile], dtype=np.float16)\n",
    "    next_vector_features = np.zeros([4, num_vf], dtype=np.float16)\n",
    "\n",
    "    next_states = [[], [], [], []]\n",
    "\n",
    "    step = 0\n",
    "    agent_step = [0, 0, 0, 0]\n",
    "\n",
    "    while not done and step < max_steps:\n",
    "\n",
    "        who, what = env.who_do_what()\n",
    "\n",
    "        ## make selection\n",
    "        if what == \"play\":\n",
    "\n",
    "            ######################## Draw a tile #####################\n",
    "\n",
    "            next_states[who], r, done, _ = env.step_draw(playerNo=who)\n",
    "\n",
    "            episode_dones[who, agent_step[who]] = done\n",
    "            episode_matrix_features[who, agent_step[who]] = this_states[who][0]\n",
    "            episode_vector_features[who, agent_step[who]] = this_states[who][1]\n",
    "            episode_rewards[who, agent_step[who]] = r\n",
    "            episode_actions[who, agent_step[who]] = 0\n",
    "            policy = np.zeros([mu_size, ], dtype=np.float32)\n",
    "            policy[0] += 1.\n",
    "            episode_policies[who, agent_step[who]] = policy  # only 1 available action (draw)\n",
    "\n",
    "            agent_step[who] += 1\n",
    "\n",
    "            this_states[who] = deepcopy(next_states[who])\n",
    "\n",
    "            ###################### Play a tile #######################\n",
    "            ###### 能和则和，能立直则立直 ############\n",
    "            aval_actions = env.t.get_self_actions()\n",
    "            good_actions = []\n",
    "\n",
    "            if agents[who].memory.filled_size < episode_start:  # For collecting data only\n",
    "                for a in range(len(aval_actions)):\n",
    "                    if aval_actions[a].action == mp.Action.Riichi:\n",
    "                        good_actions.append(a)\n",
    "\n",
    "                    if aval_actions[a].action == mp.Action.Tsumo:\n",
    "                        good_actions.append(a)\n",
    "            #######################################\n",
    "\n",
    "            next_aval_states = env.get_aval_next_states(who)  ## for a single player\n",
    "\n",
    "            if len(good_actions) > 0:\n",
    "                good_actions = np.reshape(good_actions, [-1, ])\n",
    "                a_in_good_as, policy = agents[who].select([np.array(next_aval_states[0])[good_actions],\n",
    "                                                           np.array(next_aval_states[1])[good_actions]])\n",
    "                action = good_actions[a_in_good_as]\n",
    "                tmp = np.zeros([mu_size, ], dtype=np.float32)\n",
    "                tmp[good_actions] = policy\n",
    "                policy = deepcopy(tmp)\n",
    "            else:\n",
    "                action, policy = agents[who].select(next_aval_states)\n",
    "                # covert policy to vector (with padding)\n",
    "                tmp = np.zeros([mu_size, ], dtype=np.float32)\n",
    "                tmp[:np.shape(policy)[0]] = policy\n",
    "                policy = deepcopy(tmp)\n",
    "\n",
    "            next_states[who], r, done, _ = env.step_play(action, playerNo=who)\n",
    "\n",
    "            next_states[who] = env.get_state_(who)\n",
    "\n",
    "            episode_dones[who, agent_step[who]] = done\n",
    "            episode_matrix_features[who, agent_step[who]] = this_states[who][0]\n",
    "            episode_vector_features[who, agent_step[who]] = this_states[who][1]\n",
    "            episode_rewards[who, agent_step[who]] = r\n",
    "            episode_actions[who, agent_step[who]] = action\n",
    "            episode_policies[who, agent_step[who]] = policy\n",
    "            agent_step[who] += 1\n",
    "\n",
    "            this_states[who] = deepcopy(next_states[who])\n",
    "\n",
    "        # step += 2\n",
    "\n",
    "        elif what == \"response\":\n",
    "            policies = [np.zeros([mu_size, ], dtype=np.float32) for _ in range(4)]\n",
    "            for i in range(4):\n",
    "                next_aval_states = env.get_aval_next_states(i)\n",
    "\n",
    "                ######################## 能和则和，能立直则立直 ##############\n",
    "                aval_actions = env.t.get_response_actions()\n",
    "                good_actions = []\n",
    "\n",
    "                if agents[i].memory.filled_size < episode_start:  # For collecting data only\n",
    "                    for a in range(len(aval_actions)):\n",
    "                        if aval_actions[a].action == mp.Action.Ron:\n",
    "                            good_actions.append(a)\n",
    "\n",
    "                        if aval_actions[a].action == mp.Action.ChanKan:\n",
    "                            good_actions.append(a)\n",
    "\n",
    "                        if aval_actions[a].action == mp.Action.ChanAnKan:\n",
    "                            good_actions.append(a)\n",
    "                ##########################################################\n",
    "                if len(good_actions) > 0:\n",
    "                    good_actions = np.reshape(good_actions, [-1, ])\n",
    "                    a_in_good_as, policies[i] = agents[i].select([np.array(next_aval_states[0])[good_actions],\n",
    "                                                                  np.array(next_aval_states[1])[good_actions]])\n",
    "                    actions[i] = good_actions[a_in_good_as]\n",
    "                    # covert policy to vector (with padding)\n",
    "                    tmp = np.zeros([mu_size, ], dtype=np.float32)\n",
    "                    tmp[good_actions] = policies[i]\n",
    "                    policies[i] = deepcopy(tmp)\n",
    "\n",
    "                else:\n",
    "                    actions[i], policies[i] = agents[i].select(next_aval_states)\n",
    "\n",
    "                    # covert policy to vector (with padding)\n",
    "                    tmp = np.zeros([mu_size, ], dtype=np.float32)\n",
    "                    tmp[:np.shape(policies[i])[0]] = policies[i]\n",
    "                    policies[i] = deepcopy(tmp)\n",
    "\n",
    "                next_states[i], rs[i], done, _ = env.step_response(actions[i], playerNo=i)\n",
    "\n",
    "                ## Note: next_states is agent's prediction, but not the true one\n",
    "\n",
    "            # table change after all players making actions\n",
    "\n",
    "            for i in range(4):\n",
    "                episode_dones[i, agent_step[i]] = done\n",
    "                episode_matrix_features[i, agent_step[i]] = this_states[i][0]\n",
    "                episode_vector_features[i, agent_step[i]] = this_states[i][1]\n",
    "                episode_rewards[i, agent_step[i]] = rs[i]\n",
    "                episode_actions[i, agent_step[i]] = actions[i]\n",
    "                episode_policies[i, agent_step[i]] = policies[i]\n",
    "                agent_step[i] += 1\n",
    "            ## next step\n",
    "            for i in range(4):\n",
    "                this_states[i] = deepcopy(next_states[i])\n",
    "\n",
    "        step += 1\n",
    "\n",
    "        # print(\"Game {}, step {}\".format(n, step))\n",
    "        #         print(env.get_phase_text())\n",
    "\n",
    "        if done:\n",
    "\n",
    "\n",
    "\n",
    "            final_score_change = env.get_final_score_change()\n",
    "\n",
    "            for i in range(4):\n",
    "\n",
    "                agents[i].statistics(i, env.t.get_result(), env.get_final_score_change(), env.t.turn,\n",
    "                                     env.t.players[i].riichi, env.t.players[i].menchin)\n",
    "\n",
    "                current_state = env.get_state_(i)\n",
    "                episode_matrix_features[i, agent_step[i]] = current_state[0]\n",
    "                episode_vector_features[i, agent_step[i]] = current_state[1]\n",
    "\n",
    "                if len(episode_dones[i]) >= 1:  # if not 1st turn end\n",
    "                    episode_dones[i, -1] = 1\n",
    "\n",
    "\n",
    "            if not np.max(final_score_change) == 0:  ## score change\n",
    "                for i in range(4):\n",
    "                    agents[i].remember_episode(episode_matrix_features[i, 0: agent_step[i]],\n",
    "                                               episode_vector_features[i, 0: agent_step[i]],\n",
    "                                               episode_rewards[i, 0: agent_step[i]],\n",
    "                                               episode_dones[i, 0: agent_step[i]],\n",
    "                                               episode_actions[i, 0: agent_step[i]],\n",
    "                                               episode_policies[i, 0: agent_step[i]],\n",
    "                                               weight=0)\n",
    "                print(' ')\n",
    "                print(env.t.get_result().result_type, end='')\n",
    "                print(\": Totally {} steps\".format(np.shape(episode_dones[0])[0]))\n",
    "\n",
    "                try:\n",
    "                    with open(\"./Paipu/\" + datetime_str + \"game{}\".format(n) + \".txt\", 'w') as fp:\n",
    "                        fp.write(mp.GameLogToString(env.t.game_log).decode('GBK'))\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "            else:\n",
    "                if np.random.rand() < 0.01 + n / 500000:  ## no score change\n",
    "                    for i in range(4):\n",
    "                        agents[i].remember_episode(episode_matrix_features[i, 0: agent_step[i]],\n",
    "                                                   episode_vector_features[i, 0: agent_step[i]],\n",
    "                                                   episode_rewards[i, 0: agent_step[i]],\n",
    "                                                   episode_dones[i, 0: agent_step[i]],\n",
    "                                                   episode_actions[i, 0: agent_step[i]],\n",
    "                                                   episode_policies[i, 0: agent_step[i]],\n",
    "                                                   weight=0)\n",
    "                    print(' ')\n",
    "                    print(env.t.get_result().result_type, end='')\n",
    "                    print(\": Totally {} steps\".format(np.shape(episode_dones[0])[0]))\n",
    "\n",
    "\n",
    "            for n_train in range(1):\n",
    "                for i in range(4):\n",
    "                    agents[i].learn(env.symmetric_matrix_features, episode_start=episode_start,\n",
    "                                    care_lose=False, logging=True, batch_size=32)\n",
    "\n",
    "\n",
    "data = {\"rons\": env.final_score_changes, \"p0_stat\": agents[0].stat, \"p1_stat\": agents[1].stat,\n",
    "        \"p2_stat\": agents[2].stat, \"p3_stat\": agents[3].stat, }\n",
    "sio.savemat(\"./final_score_changes\" + datetime_str + \".mat\", data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Check tiles\n",
    "for p in range(4):\n",
    "    hand = env.t.players[p].hand\n",
    "    print('player {}'.format(p))\n",
    "    for k in range(len(hand)):\n",
    "        print(hand[k].tile)\n",
    "for p in range(4):\n",
    "    fulus = env.t.players[p].fulus\n",
    "    print('player {}'.format(p))\n",
    "    for k in range(len(fulus)):\n",
    "        print(fulus[k].to_string())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.t.DORA[0].tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_states[0][0][:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "for i in range(4):\n",
    "    plt.pcolor(env.get_state_(i)[0])\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    plt.pcolor(env.get_next_state(0, i)[0])\n",
    "    print(env.t.get_response_actions()[0].action)\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict score (value function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.final_score_changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
