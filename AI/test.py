import MahjongPy
from naiveAI import AgentNaive, NMnaive
import tensorflow as tf
import numpy as np
from copy import deepcopy
from buffer import PrioritizedReplayBuffer

sess = tf.InteractiveSession()

class EnvMahjong:
    """
    An example mahjong environment for agent to interact with.
    """
    def __init__(self):
        pass
    
    def reset(self):
        self.turn = 0
        init_state = np.random.randint(low=0, high=2, size=[1, 34, 4, 1]).astype(np.float32)
        return init_state        
        
    def step(self, action):
        """
        param: action is an action generated by the agent (agent.select()), 
            action=None means there is no available action, just go to next state
        """
        
        next_state = np.random.randint(low=0, high=2, size=[1, 34, 4, 1]).astype(np.float32)
        score = 0.  # if next_state 胡了, score = 胡的分数, else score = 0
        
        if self.turn >= 100:
            done = 1 # done=1 means this game terminates
        else:
            done = 0
            
        info = {'turn': self.turn} # other information not included in state        
        self.turn += 1
        
        return next_state, score, done, info
    
    def get_aval_actions(self):
        N = np.random.randint(low=1, high=13)
        if N == 0:  # no available actions
            next_aval_states = None
        else:
            next_aval_states = np.random.randint(low=0, high=2, size=[N, 34, 4, 1]).astype(np.float32)
                
        return next_aval_states   

if __name__ == '__main__':

    nn = NMnaive(sess)
    env = EnvMahjong()

    # before the train start, create 4 agents.
    memory = PrioritizedReplayBuffer(state_dim=34*4, action_dim=34)
    agent = AgentNaive(nn, memory)
    n_games = 2

    for n in range(n_games):
        done = 0
        this_state = env.reset()
        step = 0
        while not done and step < 10000:
            next_aval_states = env.get_aval_actions()
            action, policy = agent.select(next_aval_states)
            next_state, score, done, info = env.step(action)
            agent.remember(this_state, action, next_state, score, done, next_aval_states, policy)
            agent.learn()
            this_state = deepcopy(next_state)
            step += 1
            print("Game {}, step {}".format(n, step))
            print(info)




# In[ ]:





# In[ ]:




